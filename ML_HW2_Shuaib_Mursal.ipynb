{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e545c6c4",
   "metadata": {},
   "source": [
    "Assignment: Binary Classification with Logistic Regression\n",
    "\n",
    "In this assignment, you will work with the Iris dataset to perform binary classification using logistic regression. The Iris dataset contains samples from three different species of iris flowers, but for this assignment, you will focus on classifying Iris Setosa (class 0) versus the combination of the other two classes (class 1).\n",
    "\n",
    "Here are the steps you need to follow for this assignment:\n",
    "\n",
    "Step 1: Load the Iris dataset\n",
    "\n",
    "Load the Iris dataset using sklearn.datasets.load_iris().\n",
    "Extract the feature matrix X and the target vector y.\n",
    "\n",
    "\n",
    "Step 2: Preprocess the data\n",
    "\n",
    "To convert this problem into binary classification, create a new target vector y_binary where Iris Setosa (class 0) is labeled as 1, and the other two classes are labeled as 0.\n",
    "\n",
    "\n",
    "Step 3: Split the dataset\n",
    "\n",
    "Split the dataset into training and testing sets using train_test_split() from sklearn.model_selection.\n",
    "Use 80% of the data for training and 20% for testing. Set the random_state to ensure reproducibility.\n",
    "\n",
    "Step 4: Define the cost function (logistic loss)\n",
    "\n",
    "Implement the logistic loss function, which calculates the cost of your model's predictions.\n",
    "\n",
    "Step 5: Define the training function\n",
    "\n",
    "Implement a training function that uses gradient descent to optimize the logistic regression model.\n",
    "The function should take input data, learning rate, number of iterations, and regularization parameter as arguments.\n",
    "\n",
    "Step 6: Train the model\n",
    "\n",
    "Use the training function to train your logistic regression model on the training data.\n",
    "Obtain the weight vector W and bias term b.\n",
    "\n",
    "\n",
    "Step 7: Define the prediction function\n",
    "\n",
    "Implement a prediction function that takes input data and the trained model's weights and bias.\n",
    "The prediction function should use the logistic sigmoid function to make binary predictions (0 or 1).\n",
    "\n",
    "\n",
    "Step 8: Predict on the test set\n",
    "\n",
    "Use the prediction function to predict the classes for the test set X_test using the obtained weights and bias.\n",
    "\n",
    "\n",
    "Step 9: Evaluate the model's performance\n",
    "\n",
    "Calculate the accuracy of your model using accuracy_score() from sklearn.metrics.\n",
    "Generate the confusion matrix using confusion_matrix() from sklearn.metrics.\n",
    "Generate the classification report using classification_report() from sklearn.metrics.\n",
    "Print out the accuracy, confusion matrix, and classification report to evaluate your model's performance.\n",
    "Make sure to comment your code and provide explanations for each step. This assignment will help you understand the basics of binary classification, logistic regression, and how to evaluate the performance of your model using various metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f956686e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9effbccb",
   "metadata": {},
   "source": [
    "## Step 1: Load the Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0d500c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris['data']\n",
    "Y=iris['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3fd8cc",
   "metadata": {},
   "source": [
    "## Step 2: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e1133fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_class0 = np.zeros((100,1))\n",
    "y_class1 = np.ones((50,1))\n",
    "Y = np.vstack((y_class1,y_class0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8bbe8a",
   "metadata": {},
   "source": [
    "## Step 3: Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "87bd5f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50297d42",
   "metadata": {},
   "source": [
    "## Step 4: Logistic Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "471421ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Myloss(y, yhat):\n",
    "    loss = -np.sum(Y * np.log(yhat) + (1 - Y) * np.log(1 - yhat))\n",
    "    return loss\n",
    "def Mysigmoid(z):\n",
    "    return 1 / (1+ np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11c75bd",
   "metadata": {},
   "source": [
    "## Step 5: Training Function - Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "37e57529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyGradient(X, Y, theta, aplha, iterations):\n",
    "    m = len(X)\n",
    "    for i in range(iterations):\n",
    "        z = np.dot(X, theta)\n",
    "        yhat = Mysigmoid(z)\n",
    "        w_gradient = (1 / m) * np.dot(X.T, (yhat - Y))\n",
    "        b_gradient = (1 / m) * np.sum(yhat - Y)\n",
    "        theta -= alpha*w_gradient\n",
    "        return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fde9d8a",
   "metadata": {},
   "source": [
    "## Step 6: Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fa77f359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.124125]\n",
      " [-0.038   ]\n",
      " [-0.138   ]\n",
      " [-0.051   ]]\n"
     ]
    }
   ],
   "source": [
    "n_features = X.shape[1]\n",
    "theta = np.zeros((n_features,1))\n",
    "b = 0\n",
    "alpha = 0.1\n",
    "iterations = 1000\n",
    "# Perform gradient descent to learn theta\n",
    "theta = MyGradient(X_train, Y_train, theta, alpha, iterations)\n",
    "\n",
    "# Predict on training and test data\n",
    "y_train_pred = (Mysigmoid(np.dot(X_train, theta)) >= 0.5).astype(int)\n",
    "y_test_pred = (Mysigmoid(np.dot(X_test, theta)) >= 0.5).astype(int)\n",
    "\n",
    "# Calculate accuracy\n",
    "train_accuracy = accuracy_score(Y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(Y_test, y_test_pred)\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bf5c13a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
